---
slug: offline-first-structure
title: Offline-first Structure
authors:
  name: Christopher Kiessling
  title: Ninja Software Engineer
  url: https://github.com/crsk
  image_url: https://github.com/crsk.png
tags: []
---

import codeFlow from './code-flow.png'
import costRepair from './cost-repair.png'
import reduxQueue from './redux-queue.png'
import syncFlow from './sync-flow.png'

# Offline first

1. Store user node movements locally with Redux
2. Run bulk operations when syncing changes with the server.

## Implementation

### Libraries

I'm going to use a set of libraries that will help with implementing a solid base to start building from, these are:

- Redux: Predictable state container for JavaScript apps.
- Redux-toolkit: Toolset for efficient Redux development.
- Redux-observable: RxJS-based middleware for Redux. Compose and cancel async actions.
- Redux-persist: Persist and rehydrate a redux store.
- Async-storage: Storage engine.

### Flux architecture

Flux is a well-established pattern used to manage data flow in React applications. Redux, a popular implementation of Flux, efficiently handles asynchronous operations as illustrated here:
![Async Redux flow animation](https://redux.js.org/assets/images/ReduxAsyncDataFlowDiagram-d97ff38a0f4da0f327163170ccc13e80.gif)

<div className="caption">https://redux.js.org/tutorials/fundamentals/part-6-async-logic</div>

However, to further enhance this mechanism, let's extend it to support RxJS and persistence over a queue mechanism. By doing so, the resulting implementation will have the capability to handle complex data flows and ensure data persistence even in case of network disruptions. The following image demonstrates the end result:

<img src={reduxQueue} />
<div className="caption">Redux queue flow</div>

<img src={syncFlow} />
<div className="caption">Redux synchronization flow</div>

### Code

<img src={codeFlow} />
<div className="caption">Simplified overview</div>

I've created a `handleRemoteEpic` function to easily include operations other than "Add", it also avoids calling the API if the user is not logged in:

```tsx
const handleRemoteEpic =
  (actionType: string, apiMethod: (payload: any) => Promise<any>): Epic<any, any, RootState> =>
  (action$, state$) =>
    action$.pipe(
      ofType(actionType),
      debounceTime(DEBOUNCE_TIME),
      switchMap(
        ({ payload }: { payload: any }) =>
          state$.value.login?.user
            ? from(apiMethod(payload)).pipe(
                map(() => ({ type: ActionEnumMap[actionType], payload })),
                catchError(() => storeLocalHandler(actionType, payload))
              )
            : storeLocalHandler(actionType, payload) // no user logged in, nothing to save in the backend
      )
    )

const addNodeEpic = handleRemoteEpic(addNodeTrigger.type, nodeApi.create)
const deleteNodeEpic = handleRemoteEpic(deleteNodeTrigger.type, nodeApi.delete)
const updateNodeEpicRemote = handleRemoteEpic(updateNodeTrigger.type, nodeApi.update)
```

```tsx
const ActionEnumMap: Record<string, NodeActionTypes> = {
  [addNodeTrigger.type]: NodeActionTypes.ADD,
  [updateNodeTrigger.type]: NodeActionTypes.UPDATE,
  [deleteNodeTrigger.type]: NodeActionTypes.DELETE,
}

const QueueActionEnumMap: Record<string, QueueActionTypes> = {
  [addNodeTrigger.type]: QueueActionTypes.ADD_NODE,
  [updateNodeTrigger.type]: QueueActionTypes.UPDATE_NODE,
  [deleteNodeTrigger.type]: QueueActionTypes.DELETE_NODE,
}
const storeLocalHandler = (actionType: string, payload: any) =>
  concat(of({ type: QueueActionEnumMap[actionType], payload }), of({ type: ActionEnumMap[actionType], payload }))
```

### Synchronization logic

After some offline activity, our queue should look something like this:

```ts
QUEUE: {
  NODE: {
    ADD: {
      'some-client-side-generated-id': {
        id: 'some-client-side-generated-id',
        parentId: 'some-other-client-side-id',
        x: 300,
        y: 600,
      },
      'some-client-side-generated-id': {
        id: 'some-client-side-generated-id',
        parentId: 'some-other-client-side-id',
        x: 400,
        y: 800,
      },
    },
    UPDATE: {
      'some-client-side-generated-id': {
        id: 'some-client-side-generated-id',
        propsToUpdate: {
          x: 1200,
          y: 720,
        },
      },
    },
    DELETE: {
      'some-client-side-generated-id': {
        id: 'some-client-side-generated-id',
      },
      'some-client-side-generated-id': {
        id: 'some-client-side-generated-id',
      },
    }
  }
}
```

Let's iterate through and call the bulk-creation API

```tsx
const syncEpic: Epic<any, any, RootState> = (action$, state$) =>
  action$.pipe(
    ofType(syncNodesTrigger.type),
    mergeMap(() => {
      const { ADD, UPDATE, DELETE }: QueueOperation<CreateNodeBody, UpdateNodeBody, DeleteNodeParams> =
        state$.value.queue.NODE
      const unsyncedNodes: {
        actionType: QueueActionTypes
        payload: CreateNodeBody | UpdateNodeBody | DeleteNodeParams
      }[] = [
        ...Object.values(ADD).map(payload => ({
          actionType: QueueActionTypes.ADD_NODE,
          payload,
        })),
        ...Object.values(UPDATE).map(payload => ({
          actionType: QueueActionTypes.UPDATE_NODE,
          payload,
        })),
        ...Object.values(DELETE).map(payload => ({
          actionType: QueueActionTypes.DELETE_NODE,
          payload,
        })),
      ]

      return unsyncedNodes.length === 0
        ? EMPTY
        : from(unsyncedNodes).pipe(
            groupBy(node => node.actionType),
            mergeMap(group => group.pipe(toArray())),
            concatMap(actionGroup => {
              const { actionType } = actionGroup[0]

              switch (actionType) {
                case QueueActionTypes.ADD_NODE:
                  return from(nodeApi.bulkCreate(actionGroup.map(action => action.payload as CreateNodeBody))).pipe(
                    mergeMap(() =>
                      actionGroup.map(action => ({
                        type: QueueActionTypes.DELETE_FROM_QUEUE,
                        payload: {
                          operation: 'ADD',
                          id: (action.payload as CreateNodeBody).id,
                        },
                      }))
                    ),
                    catchError(() => EMPTY)
                  )
                case QueueActionTypes.UPDATE_NODE:
                  return from(nodeApi.bulkUpdate(actionGroup.map(action => action.payload as UpdateNodeBody))).pipe(
                    mergeMap(() =>
                      actionGroup.map(action => ({
                        type: QueueActionTypes.DELETE_FROM_QUEUE,
                        payload: {
                          operation: 'UPDATE',
                          id: (action.payload as UpdateNodeBody).id,
                        },
                      }))
                    ),
                    catchError(() => EMPTY)
                  )
                case QueueActionTypes.DELETE_NODE:
                  return from(nodeApi.bulkDelete(actionGroup.map(action => action.payload as UpdateNodeBody))).pipe(
                    mergeMap(() =>
                      actionGroup.map(action => ({
                        type: QueueActionTypes.DELETE_FROM_QUEUE,
                        payload: {
                          operation: 'DELETE',
                          id: (action.payload as DeleteNodeParams).id,
                        },
                      }))
                    ),
                    catchError(() => EMPTY)
                  )
                default:
                  return EMPTY
              }
            })
          )
    })
  )
```

### Server side

Finally, let's check if the current node in the bulk operation has an already non-inserted parent (Nodes should be created by their parents first). If so, commit the transaction and start a new one for the upcoming inserts.

```tsx
export const runTransaction = async <T extends QueryResult>(
  queries: Array<{ query: string; id: string }>
): Promise<T[]> =>
  withConnection(async (client: PoolClient) => {
    try {
      await client.query('BEGIN')
      const results = await Promise.all(queries.map(({ query }) => client.query<T>(query)))
      await client.query('COMMIT')

      return results as T[]
    } catch (err) {
      console.error('Transaction error:', err)
      await client.query('ROLLBACK')
      throw err
    }
  })
```

```tsx
export const createNodes = async (newNodes: SnakeCase<CreateNodeBody>[]): Promise<number | undefined> => {
  let transactionQueries: { query: string; id: string }[] = []
  const queryResult = []

  const commitTransaction = async () => {
    if (transactionQueries.length > 0) {
      const results = await runTransaction(transactionQueries)
      queryResult.push(...results)
      transactionQueries = []
    }
  }

  for (const node of newNodes) {
    const isParentInTransaction = transactionQueries.some(q => q.id === node.parent_id)
    if (isParentInTransaction) await commitTransaction()

    const columns = Object.keys(node)
    const values = Object.values(node)
    const query = format('INSERT INTO %I (%I) VALUES (%L)', 'node', columns, values)

    transactionQueries.push({ query, id: node.id })
  }
  await commitTransaction()

  return queryResult.length
}
```
